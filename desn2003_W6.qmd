---
title: "DESN2003: Research for Innovation"
subtitle: "Week 6: Methods II — Quantitative & Mixed Methods"
author: "Dr. Hongshan Guo"
format:
  revealjs:
    slide-number: true
    theme: simple
    width: 1600
    height: 1200
    embed-resources: true
    incremental: true
    center: true
    footer: "DESN2003 Research for Innovation"
---

# Building on Last Week {background-color="#4ECDC4"}

## The Methods Landscape

::: {.columns}
::: {.column width="50%"}
**Last Week: Qualitative**

- Interviews (structured, semi-structured)
- Observations & ethnography
- Case studies
- Rich, descriptive data
- Understanding the "why"
:::

::: {.column width="50%"}
**This Week: Quantitative & Mixed**

- Surveys & questionnaires
- Experiments & A/B tests
- Combining approaches
- Numerical data
- Measuring the "how much"
:::
:::

. . .

::: {.callout-important icon=false}
## Today's Question
When do you need numbers? When do you need both? How do you design research that gives you credible, useful data?
:::

---

## Today's Roadmap

::: {.nonincremental}
1. **Quantitative Methods Overview** — When numbers matter
2. **Survey Design** — Creating effective questionnaires
3. **Experimental Methods** — Testing cause and effect
4. **Mixed Methods** — Combining qual and quant
5. **Activity: Design Your Data Collection**
6. **Doc 0.1 Check-in** — Due today!
:::

---

## Learning Objectives

By the end of this session, you will be able to:

::: {.incremental}
1. **Identify** when quantitative methods are appropriate for your research question
2. **Design** survey questions that avoid common pitfalls
3. **Understand** the logic of experimental design and A/B testing
4. **Plan** a mixed-methods approach that leverages both qual and quant strengths
:::

---

## Assessment Reminder

::: {.callout-warning icon=false}
## Doc 0.1: Literature Review — Due Today!

**Tuesday, Mar 3, 12:00 PM noon**

If you haven't submitted yet, do so before class ends.

Your literature review should show:
- What's already known about your topic
- What methods others have used
- Where the gaps remain
:::

# Quantitative Methods Overview {background-color="#A8DADC"}

## When Do You Need Numbers?

Quantitative research is appropriate when you need to:

::: {.incremental}
- **Measure** the frequency, magnitude, or distribution of something
- **Compare** groups or conditions systematically
- **Test** whether a relationship or difference is "real" (statistically)
- **Generalize** findings to a larger population
- **Validate** something you discovered qualitatively
:::

. . .

::: {.callout-note icon=false}
## The Key Question
"How many?" or "How much?" → Quantitative

"Why?" or "How does it work?" → Qualitative (or start there first)
:::

---

## Common Quantitative Methods

| Method | What It Does | Best For |
|--------|--------------|----------|
| **Survey/Questionnaire** | Collects self-reported data from many people | Measuring attitudes, behaviors, demographics at scale |
| **Experiment** | Manipulates variables to test causation | Testing if an intervention causes an effect |
| **A/B Test** | Compares two versions with random assignment | Testing design changes in real products |
| **Analytics/Log Analysis** | Examines behavioral data from systems | Understanding actual usage patterns |
| **Correlation Study** | Measures relationships between variables | Identifying what goes together (not causation) |

---

## Real Paper Example: Survey Research

::: {.callout-note icon=false}
## Exploring the Impact of Publicness of Public Space in Hong Kong

**Paper:** [Exploring the Impact of the Publicness of Public Space in Hong Kong: A Structural Equation Modelling Approach](https://www.mdpi.com/2073-445X/14/1/91) (Land, 2025)

**Method:** Two questionnaire surveys (n=305) measuring five impact dimensions: effectiveness, fairness, sense of ease, meaningfulness, friendliness

**What makes it work:**
- Clear conceptual framework (publicness → impacts)
- Rigorous statistical analysis (SEM)
- Specific context (HK public spaces)
- Actionable findings for urban designers
:::

Survey research can be publishable — but you need clear constructs and proper analysis.

---

## Quantitative Data Types

::: {.columns}
::: {.column width="50%"}
### Categorical (Nominal/Ordinal)

**Nominal:** Categories without order
- Gender, nationality, device type

**Ordinal:** Categories with order
- Likert scales (strongly disagree → strongly agree)
- Education level, satisfaction ranking
:::

::: {.column width="50%"}
### Numerical (Interval/Ratio)

**Interval:** Equal intervals, no true zero
- Temperature, dates

**Ratio:** Equal intervals, true zero
- Age, time on task, number of errors, revenue
:::
:::

. . .

::: {.callout-tip icon=false}
## Why This Matters
Your data type determines what statistics you can use. You can't calculate a meaningful average of "device type," but you can count frequencies.
:::

# Survey Design {background-color="#FFE66D"}

## Surveys: Power and Pitfalls

::: {.columns}
::: {.column width="50%"}
**Strengths:**

- Reach many people efficiently
- Standardized data collection
- Can cover diverse topics
- Relatively low cost
- Anonymous → more honest?
:::

::: {.column width="50%"}
**Limitations:**

- Self-report bias (what people say ≠ what they do)
- Question wording matters enormously
- Low response rates common
- Can't probe deeper
- Misses context
:::
:::

---

## Types of Survey Questions

::: {.columns}
::: {.column width="50%"}
### Closed-Ended

**Dichotomous:** Yes/No, True/False

**Multiple Choice:** Select one option

**Checkbox:** Select all that apply

**Likert Scale:** Agreement/frequency rating

**Ranking:** Order items by preference
:::

::: {.column width="50%"}
### Open-Ended

**Free text:** Short answer or paragraph

- Richer data but harder to analyze
- Good for "other" options
- Use sparingly in large surveys
:::
:::

. . .

::: {.callout-note icon=false}
## For Analysis
Closed-ended → Easy to quantify, compare, graph

Open-ended → Requires coding/thematic analysis (essentially qualitative data)
:::

---

## Designing Good Survey Questions

::: {.columns}
::: {.column width="50%"}
**Do:**

- Keep questions short and clear
- Ask one thing at a time
- Use neutral wording
- Provide balanced response options
- Include "N/A" or "Don't know" when appropriate
- Pilot test with real users
:::

::: {.column width="50%"}
**Don't:**

- Use jargon or technical terms
- Ask leading questions
- Use double negatives
- Assume knowledge
- Force answers (when respondent may not have opinion)
- Make surveys too long
:::
:::

---

## Common Survey Mistakes

::: {.columns}
::: {.column width="50%"}
### Leading Question

"Don't you agree that our new feature is helpful?"

**Better:** "How helpful do you find the new feature?"

### Double-Barreled

"How satisfied are you with the speed and design of the app?"

**Better:** Ask about speed and design separately
:::

::: {.column width="50%"}
### Loaded Language

"How often do you waste time on social media?"

**Better:** "How much time do you spend on social media daily?"

### Unclear Scale

"Rate your experience: Good / Bad"

**Better:** 5-point scale with labeled endpoints
:::
:::

---

## Likert Scales: Best Practices

::: {.callout-note icon=false}
## Standard 5-Point Agreement Scale
1. Strongly disagree
2. Disagree
3. Neither agree nor disagree
4. Agree
5. Strongly agree
:::

**Tips:**

::: {.incremental}
- Use odd numbers (5 or 7) to allow neutral midpoint
- Label all points, not just endpoints
- Keep scale direction consistent throughout survey
- Consider whether midpoint is meaningful for your question
- 7-point scales capture more nuance; 5-point is simpler
:::

---

## Survey Flow & Structure

::: {.callout-tip icon=false}
## A Logical Survey Structure

1. **Introduction:** Purpose, time estimate, confidentiality
2. **Screening questions:** Verify respondent eligibility
3. **Easy warm-up questions:** Build engagement
4. **Core questions:** The heart of your research
5. **Sensitive/demographic questions:** At the end (reduces drop-off)
6. **Thank you:** Appreciation, contact info for questions
:::

**Length matters:** Aim for 5-10 minutes max. Every additional question increases drop-off.

# Experimental Methods {background-color="#4ECDC4"}

## The Logic of Experiments

::: {.callout-important icon=false}
## Causation vs. Correlation

**Correlation:** X and Y tend to go together (doesn't prove X causes Y)

**Causation:** X actually produces Y (requires experimental control)

Experiments let you make **causal claims** by manipulating one variable and measuring its effect.
:::

---

## Basic Experimental Design

::: {.columns}
::: {.column width="50%"}
### Key Elements

1. **Independent Variable (IV):** What you manipulate (e.g., button color)

2. **Dependent Variable (DV):** What you measure (e.g., click rate)

3. **Control Group:** Receives no treatment or standard treatment

4. **Treatment Group:** Receives the intervention

5. **Random Assignment:** Participants randomly placed in groups
:::

::: {.column width="50%"}
### Why This Works

- Random assignment distributes other variables evenly
- Only difference between groups is the IV
- If DV differs between groups → IV likely caused it
- Statistical tests confirm if difference is "real" or chance
:::
:::

---

## A/B Testing: Experiments in Product

::: {.callout-note icon=false}
## A/B Test Basics

**Version A (Control):** Existing design

**Version B (Treatment):** New design

**Users randomly assigned** to A or B

**Measure:** Key metric (conversion, engagement, time on task)

**Analyze:** Is the difference statistically significant?
:::

**This is experimental design applied to real products at scale.**

---

## A/B Testing Process

::: {.nonincremental}
1. **Hypothesis:** "Changing X will improve metric Y"

2. **Design:** Create Version A and Version B (differ only in X)

3. **Sample Size:** Calculate needed sample for statistical power

4. **Randomize:** Assign users randomly to A or B

5. **Run:** Let test run until you have enough data

6. **Analyze:** Compare metrics, calculate statistical significance

7. **Decide:** If significant, implement winner; if not, iterate
:::

---

## When A/B Testing Works (and Doesn't)

::: {.columns}
::: {.column width="50%"}
**Good for:**

- Testing small, specific changes
- When you have high traffic/volume
- Binary decisions (which is better?)
- Measurable outcomes
:::

::: {.column width="50%"}
**Not good for:**

- Understanding *why* something works
- Low-traffic situations
- Complex, multi-variable changes
- Brand-new products (no baseline)
:::
:::

. . .

::: {.callout-tip icon=false}
## Complement with Qualitative
A/B test shows *that* B is better. Interviews/observations explain *why*.
:::

# Mixed Methods {background-color="#A8DADC"}

## Why Mix Methods?

::: {.columns}
::: {.column width="50%"}
**Qualitative Alone:**

- Rich understanding of "why"
- But: Limited generalizability
- But: "How common is this?"
:::

::: {.column width="50%"}
**Quantitative Alone:**

- Measures "how much/how many"
- But: Misses the "why"
- But: May miss unexpected findings
:::
:::

. . .

::: {.callout-important icon=false}
## Mixed Methods = Best of Both
- Qualitative explores → Quantitative validates
- Quantitative identifies → Qualitative explains
- Triangulation increases confidence
:::

---

## Common Mixed Methods Designs

::: {.columns}
::: {.column width="50%"}
### Sequential Exploratory

**Qual → Quant**

1. Interviews explore the problem
2. Themes inform survey design
3. Survey tests how widespread themes are

*Use when:* You don't know enough to design a survey yet
:::

::: {.column width="50%"}
### Sequential Explanatory

**Quant → Qual**

1. Survey/analytics identify a pattern
2. Interviews explain why the pattern exists
3. Rich understanding of the numbers

*Use when:* You see something in data but don't know why
:::
:::

---

## Mixed Methods in Action

::: {.callout-note icon=false}
## Example: Studying AI Tool Adoption

**Phase 1 (Qualitative):**
Interview 10 students about their AI tool experiences → Identify themes: "time-saving," "uncertainty about accuracy," "guilt about using it"

**Phase 2 (Quantitative):**
Survey 200 students using questions based on themes → Find: 65% report time-saving, 78% express accuracy concerns, 45% report guilt

**Result:**
Rich understanding (Phase 1) + Prevalence data (Phase 2)
:::

---

## Real Paper Example: Computational + Qualitative

::: {.callout-note icon=false}
## Voice From the City: Public Sentiments Across Urban Open Spaces

**Paper:** [Voice From the City: Public Sentiments Across Different Types of Urban Open Spaces in Hong Kong](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5554296) (SSRN, 2025)

**Method:**
- **Quantitative:** Sentiment analysis and NLP on public comments
- **Qualitative:** Thematic analysis of comment content
- **Spatial:** GIS mapping of sentiment across space types

**What makes it work:**
- Novel data source (public sentiment data)
- Mixed methods triangulation
- Connects computational analysis to design implications
- Specific to HK context
:::

Computational methods + qualitative interpretation = publishable research.

---

## Choosing Your Approach

| Your Situation | Recommended Approach |
|---------------|---------------------|
| "I don't know what's happening" | Start qualitative, then quantify |
| "I see a pattern but don't understand it" | Start quantitative, then explain with qual |
| "I need both depth and breadth" | Concurrent or sequential mixed methods |
| "I need to test a specific hypothesis" | Quantitative (experiment or survey) |
| "I need to understand complex experiences" | Qualitative (interviews, ethnography) |

# Activity: Design Your Data Collection {background-color="#FFE66D"}

## Your Task (20 minutes)

**Based on your research question and method thinking from Week 5:**

::: {.nonincremental}
1. **Decide:** Would quantitative methods help answer your question? What about mixed methods?

2. **Design ONE of the following:**

   **Option A: Survey Questions**
   - Draft 5 survey questions related to your research
   - Include at least one Likert scale question
   - Avoid the common mistakes we discussed

   **Option B: Data Collection Plan**
   - What data do you need?
   - Who will you collect it from?
   - What method(s) will you use?
   - Qual first? Quant first? Both?

3. **Identify:** What are the limitations of your approach?
:::

---

## Share & Feedback (10 minutes)

**Exchange with a neighbor:**

::: {.nonincremental}
- Review their survey questions OR data collection plan
- Check for: Clarity, bias, feasibility
- For surveys: Are questions leading? Double-barreled? Clear?
- For plans: Does the method match the question?
:::

. . .

**Give one specific suggestion for improvement.**

---

## Debrief

::: {.incremental}
- Who designed survey questions? What was hardest?
- Who planned a mixed methods approach? How will you sequence them?
- What limitations did you identify in your own approach?
- How will your literature review (Doc 0.1) inform your final method choice?
:::

# Looking Ahead {background-color="#457B9D"}

## Your Methods Journey

::: {.callout-note icon=false}
## Where You Are Now

**You have:**
- A research question (Week 4)
- Understanding of qualitative methods (Week 5)
- Understanding of quantitative & mixed methods (Today)
- A literature review showing what others have done (Doc 0.1)

**Coming up:**
- Week 7: Analysis — How do you make sense of the data you collect?
- Doc 0.2: Collecting Evidence — Your actual data collection plan
:::

---

## From Methods to Evidence

::: {.columns}
::: {.column width="50%"}
**Doc 0.2: Collecting Evidence**

Due: Week 10 (Mar 31)

- Your methodology section
- What data will you collect?
- What method will you use?
- How will you analyze it?
- What are the limitations?
:::

::: {.column width="50%"}
**Use the next few weeks to:**

- Refine your method based on Doc 0.1 feedback
- Start planning logistics (who to interview, what to survey)
- Consider ethics and access
- Think about your analysis approach
:::
:::

---

## Connecting It All

::: {.callout-important icon=false}
## The Research Logic Chain

**Question:** "How do [population] experience [phenomenon]?"

↓

**Method:** Interviews (if exploring) or Survey (if measuring prevalence)

↓

**Data:** Transcripts (qual) or Responses (quant)

↓

**Analysis:** Thematic analysis (qual) or Statistics (quant)

↓

**Findings:** Themes with quotes OR Percentages with significance tests

Your method choice shapes everything downstream.
:::

# Key Takeaways {background-color="#457B9D"}

## What We Learned Today

::: {.nonincremental}
1. **Quantitative methods** measure "how much/how many" — use when you need numbers, comparisons, or generalization

2. **Survey design** requires careful attention to wording — avoid leading, double-barreled, and biased questions

3. **Experiments** allow causal claims through manipulation and random assignment — A/B tests are experiments in product settings

4. **Mixed methods** combine qual and quant strengths — explore then validate, or identify then explain

5. **Method follows question** — choose based on what you need to know, not what seems easiest

6. **Triangulation builds confidence** — multiple methods pointing to the same finding strengthens your conclusions
:::

---

## The Bridge

::: {.columns}
::: {.column width="50%"}
**Today (Week 6)**

Methods II: Quantitative & Mixed

- Surveys, experiments, A/B tests
- Combining qual and quant
- Doc 0.1 due!
:::

::: {.column width="50%"}
**Next Week (Week 7)**

Analysis: Making Sense of Data

- How do you analyze qualitative data?
- How do you analyze quantitative data?
- From data to findings
:::
:::

. . .

**Your research journey:**

Instinct → Gap → Landscape → Question → **Methods** → Evidence → Analysis → Paper

---

## Questions?

::: {.r-fit-text}
Let's discuss!
:::

**Office hours:** By appointment

**Next week:** Analysis — Making Sense of Your Data

**Doc 0.2 due:** Week 10 (Mar 31)

::: {.notes}
- Check: Has everyone submitted Doc 0.1?
- Encourage thinking about methods as they await feedback
- Remind them that method choice will be refined based on lit review insights
:::
